{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Core tools for working with storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from abc import ABC,abstractmethod\n",
    "from configparser import ConfigParser\n",
    "from pathlib import Path\n",
    "import shutil, boto3 as aws, azure.storage.blob as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "from configparser import SectionProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_config(section_name=None,config_name='secrets//settings.ini'):\n",
    "    config_path=Path(config_name)\n",
    "    config=ConfigParser()\n",
    "    config.read(config_path)\n",
    "    if section_name is None:\n",
    "        return config\n",
    "    if section_name not in config:\n",
    "        raise Exception(f'Error: [{section_name}] section not found in {config_path}')\n",
    "    return dict(config.items(section_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(read_config(),ConfigParser)\n",
    "assert isinstance(read_config()['DEFAULT'],SectionProxy)\n",
    "assert isinstance(read_config('DEFAULT'),dict)\n",
    "assert read_config('DEFAULT')['local_path']=='data'\n",
    "assert read_config('local_cwd',config_name='test//secrets//settings.ini')['storage_type']=='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StorageClientABC(ABC):\n",
    "    \"\"\"Defines functionality common to all storage clients\"\"\"\n",
    "    \n",
    "    def __init__(self,storage_name,config_name='secrets//settings.ini'):\n",
    "        \"Create a new storage client using the `storage_name` section of `config_name`\"\n",
    "        self.config=read_config(storage_name,config_name=config_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def ls(self,what):\n",
    "        \"Return a list containing the names of files in either `storage_area` or `local_path`\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    def download(self,filename): \n",
    "        \"Copy `filename` from `storage_area` to `local_path`\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def upload(self,filename,overwrite=False): \n",
    "        \"Copy `filename` from `local_path` to `storage_area`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LocalStorageClient(StorageClientABC):\n",
    "    \"\"\"Storage client that uses the local filesystem for both `storage_area` and `local_path`\"\"\"\n",
    "    \n",
    "    def _ls(self,p,result,len_path_prefix):\n",
    "        for _p in p.iterdir():\n",
    "            if _p.is_dir(): self._ls(_p,result,len_path_prefix)\n",
    "            else: result.append(str(_p).replace('\\\\','/')[len_path_prefix:])\n",
    "\n",
    "    def ls(self,what='storage_area'):\n",
    "        result,p=[],Path(self.config[what])\n",
    "        p.mkdir(parents=True,exist_ok=True)\n",
    "        self._ls(p,result,len(self.config[what])+1)\n",
    "        sorted(result)\n",
    "        return result\n",
    "        \n",
    "    def _cp(self,from_key,to_key,filename,overwrite=False):\n",
    "        src=Path(self.config[from_key])/filename\n",
    "        dst=Path(self.config[to_key])/filename\n",
    "        if dst.exists() and not overwrite: \n",
    "            raise FileExistsError(f'{dst} exists and overwrite=False')\n",
    "        dst.parent.mkdir(parents=True,exist_ok=True)\n",
    "        shutil.copy(src,dst)\n",
    "        \n",
    "    def download(self,filename,overwrite=False):\n",
    "        try: self._cp('storage_area','local_path',filename,overwrite)\n",
    "        except FileExistsError: pass\n",
    "        \n",
    "    def upload(self,filename,overwrite=False): \n",
    "        self._cp('local_path','storage_area',filename,overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LocalStorageClient` will most often be used for local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client=LocalStorageClient('local_test','test//secrets//settings.ini')\n",
    "assert storage_client.config['storage_type']=='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AzureStorageClient(StorageClientABC):\n",
    "    \"\"\"Storage client that uses Azure for `storage_area` and the local filesystem `local_path`\"\"\"\n",
    "    def _client(self):\n",
    "        if getattr(self,'client') is None:\n",
    "            service_client=az.BlobServiceClient.from_connection_string(\n",
    "                self.config['conn_str'],self.config['credential'])\n",
    "            self.client=service_client.get_container_client(self.config['container'])\n",
    "        return self.client\n",
    "    def ls(self): pass \n",
    "    def download(self,filename): pass \n",
    "    def upload(self,filename,overwrite=False): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AwsStorageClient(StorageClientABC):\n",
    "    \"\"\"Storage client that uses AWS for `storage_area` and the local filesystem `local_path`\"\"\"\n",
    "    def ls(self): pass \n",
    "    def download(self,filename): pass \n",
    "    def upload(self,filename,overwrite=False): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def new_storage_client(storage_name,config_name='secrets//settings.ini'):\n",
    "    \"Returns a storage client based on the configured `storage_type`\"\n",
    "    config=read_config(storage_name,config_name=config_name)\n",
    "    storage_type=config['storage_type']\n",
    "    if storage_type=='local': return LocalStorageClient(storage_name, config_name)\n",
    "    elif storage_type=='azure': return AzureStorageClient(storage_name, config_name)\n",
    "    elif storage_type=='aws': return AwsStorageClient(storage_name, config_name)\n",
    "    else: raise ValueError(f'Unknown storage_type: {storage_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: new_storage_client('gcp_dummy','test//secrets//settings.ini'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rmtree(p):\n",
    "    try: shutil.rmtree(p)\n",
    "    except FileNotFoundError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ['test/local_path','test/storage_area']: _rmtree(p)\n",
    "    \n",
    "storage_client=new_storage_client('local_test','test//secrets//settings.ini')\n",
    "assert isinstance(storage_client,LocalStorageClient)\n",
    "assert storage_client.config['storage_type']=='local'\n",
    "test_eq([],storage_client.ls())\n",
    "test_eq([],storage_client.ls('local_path'))\n",
    "    \n",
    "test_files=['a/b/test_data2.txt','sub/test_data1.txt','test_data.txt']\n",
    "for i,f in enumerate(test_files):\n",
    "    f='test/local_path/'+f\n",
    "    Path(f).parent.mkdir(parents=True,exist_ok=True)\n",
    "    with open(f, 'w') as _file: _file.write(f'a little bit of data {i}')\n",
    "test_eq([],storage_client.ls())\n",
    "test_eq(test_files,storage_client.ls('local_path'))\n",
    "        \n",
    "for f in test_files: storage_client.upload(f)\n",
    "test_eq(test_files,storage_client.ls())\n",
    "test_eq(test_files,storage_client.ls('local_path'))\n",
    "_rmtree('test/local_path')\n",
    "test_eq([],storage_client.ls('local_path'))\n",
    "\n",
    "for f in test_files: storage_client.download(f)\n",
    "test_eq(test_files,storage_client.ls('local_path'))\n",
    "test_eq('a little bit of data 2',open('test/local_path/test_data.txt').read())\n",
    "\n",
    "with open('test/local_path/test_data.txt', 'w') as _file: _file.write('upd')\n",
    "test_eq('upd',open('test/local_path/test_data.txt').read())\n",
    "storage_client.download('test_data.txt')\n",
    "test_eq('upd',open('test/local_path/test_data.txt').read())\n",
    "storage_client.download('test_data.txt',True)\n",
    "test_eq('a little bit of data 2',open('test/local_path/test_data.txt').read())\n",
    "\n",
    "test_fail(lambda: storage_client.upload('test_data.txt'))\n",
    "storage_client.upload('test_data.txt',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client=new_storage_client('azure_dummy','test//secrets//settings.ini')\n",
    "assert isinstance(storage_client,AzureStorageClient)\n",
    "storage_client=new_storage_client('aws_dummy','test//secrets//settings.ini')\n",
    "assert isinstance(storage_client,AwsStorageClient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
